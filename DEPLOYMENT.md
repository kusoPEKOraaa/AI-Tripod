# AI-Tripod (ModelVerse) éƒ¨ç½²æŒ‡å—

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

AI-Tripod æ˜¯ä¸€ä¸ªåŸºäº ModelVerse çš„ LLM æ¨¡å‹ä¸€ä½“åŒ–æ¨è®­å¹³å°ï¼Œæä¾›æ¨¡å‹ç®¡ç†ã€æ¨ç†éƒ¨ç½²ã€è®­ç»ƒå¾®è°ƒå’Œæ€§èƒ½è¯„ä¼°åŠŸèƒ½ã€‚

---

## ğŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚
| ç»„ä»¶ | æœ€ä½é…ç½® | æ¨èé…ç½® |
|------|----------|----------|
| CPU | 4æ ¸ | 8æ ¸+ |
| å†…å­˜ | 16GB | 32GB+ |
| GPU | NVIDIA GPU (8GBæ˜¾å­˜) | NVIDIA GPU (16GB+æ˜¾å­˜) |
| å­˜å‚¨ | 50GB SSD | 200GB+ SSD |

### è½¯ä»¶è¦æ±‚
| è½¯ä»¶ | ç‰ˆæœ¬è¦æ±‚ |
|------|----------|
| æ“ä½œç³»ç»Ÿ | Linux (Ubuntu 20.04+) æˆ– WSL2 |
| Python | 3.10+ |
| NVIDIA Driver | 525+ |
| CUDA | 12.1+ |

> âš ï¸ **æ³¨æ„**: vLLM ä»…æ”¯æŒ Linux ç¯å¢ƒï¼ŒWindows ç”¨æˆ·è¯·ä½¿ç”¨ WSL2ã€‚

---

## ğŸš€ å¿«é€Ÿéƒ¨ç½²

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/Guiwith/ModelVerse.git
cd ModelVerse
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. å®‰è£…ä¾èµ–

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨å®Œæ•´ä¾èµ–æ¸…å•ï¼ˆæ¨èï¼Œç¡®ä¿ç‰ˆæœ¬ä¸€è‡´ï¼‰

```bash
# ä½¿ç”¨å·²éªŒè¯çš„å®Œæ•´ä¾èµ–æ¸…å• (285ä¸ªåŒ…)
pip install -r requirements-all.txt
```

> è¯´æ˜ï¼šå¦‚æœå®‰è£…è¿‡ç¨‹ä¸­å‡ºç° `protobuf` ä¸ `opentelemetry-*` æˆ– `oumi` çš„ç‰ˆæœ¬å†²çªï¼Œé€šå¸¸æ˜¯å› ä¸ºæŸäº›ç»„ä»¶å¯¹ `protobuf` çš„ä¸»ç‰ˆæœ¬è¦æ±‚ä¸åŒã€‚
> å½“å‰æ¨èä½¿ç”¨ `protobuf>=6.32,<7`ï¼ˆæ»¡è¶³ oumiï¼‰ï¼Œå¹¶å…è®¸ pip é€‰æ‹©ä¸ä¹‹å…¼å®¹çš„ `opentelemetry-*` ç‰ˆæœ¬ã€‚

#### æ–¹å¼äºŒï¼šä½¿ç”¨ PyTorch å®˜æ–¹æºå®‰è£… (CUDA 12.8)

```bash
# å®‰è£… PyTorch (CUDA 12.8)
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 --index-url https://download.pytorch.org/whl/cu128

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r modelverse/requirements.txt

# å®‰è£… oumi (è®­ç»ƒæ¡†æ¶)
pip install "oumi[gpu]==0.6.0"

# å®‰è£… vLLM (æ¨ç†å¼•æ“) - å¿…é¡»ä½¿ç”¨ä¸ PyTorch å…¼å®¹çš„ç‰ˆæœ¬
pip install "vllm==0.10.2"

# protobuf (oumi éœ€è¦)
pip install "protobuf>=6.32,<7"
```

#### æ–¹å¼äºŒï¼šä½¿ç”¨å›½å†…é•œåƒæº

```bash
# ä½¿ç”¨æ¸…åé•œåƒ
pip install torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0 -i https://pypi.tuna.tsinghua.edu.cn/simple

pip install -r modelverse/requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple

pip install "oumi[gpu]==0.6.0" -i https://pypi.tuna.tsinghua.edu.cn/simple

pip install "vllm==0.10.2" -i https://pypi.tuna.tsinghua.edu.cn/simple

pip install "protobuf>=6.32,<7" -i https://pypi.tuna.tsinghua.edu.cn/simple
```

### 4. é…ç½®ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼Œæ¨èå›½å†…ç”¨æˆ·ï¼‰

```bash
# è®¾ç½® HuggingFace é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
export HF_HUB_ENABLE_HF_TRANSFER=0
```

### 5. å¯åŠ¨æœåŠ¡

```bash
cd modelverse
python main.py
# æˆ–ä½¿ç”¨ uvicorn
uvicorn main:app --host 0.0.0.0 --port 8888
```

### 6. è®¿é—®åº”ç”¨

æ‰“å¼€æµè§ˆå™¨è®¿é—®: http://localhost:8888

**é»˜è®¤è´¦æˆ·**:
- ç”¨æˆ·å: `admin`
- å¯†ç : `admin123`

---

## ğŸ“¦ æ ¸å¿ƒä¾èµ–ç‰ˆæœ¬

ä»¥ä¸‹æ˜¯ç»è¿‡æµ‹è¯•çš„å…¼å®¹ç‰ˆæœ¬ç»„åˆï¼š

### æ ¸å¿ƒæ¡†æ¶
| åŒ…å | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| torch | 2.8.0 | PyTorch æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| torchvision | 0.23.0 | PyTorch è§†è§‰åº“ |
| torchaudio | 2.8.0 | PyTorch éŸ³é¢‘åº“ |
| vllm | 0.10.2 | é«˜æ€§èƒ½ LLM æ¨ç†å¼•æ“ |
| oumi | 0.6.0 | æ¨¡å‹è®­ç»ƒæ¡†æ¶ |
| transformers | 4.57.3 | HuggingFace Transformers |

### Web æ¡†æ¶
| åŒ…å | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| fastapi | 0.127.0 | ç°ä»£ Web API æ¡†æ¶ |
| uvicorn | 0.35.0 | ASGI æœåŠ¡å™¨ |
| pydantic | 2.12.5 | æ•°æ®éªŒè¯ |

### å…¶ä»–é‡è¦ä¾èµ–
| åŒ…å | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|
| huggingface-hub | 0.36.0 | HuggingFace Hub å®¢æˆ·ç«¯ |
| accelerate | 1.12.0 | åˆ†å¸ƒå¼è®­ç»ƒåŠ é€Ÿ |
| datasets | 4.4.2 | æ•°æ®é›†ç®¡ç† |
| evaluate | 0.4.6 | æ¨¡å‹è¯„ä¼° |
| protobuf | >=6.32,<7 | Protocol Buffers |

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
ModelVerse/
â”œâ”€â”€ modelverse/                 # ä¸»åº”ç”¨ç›®å½•
â”‚   â”œâ”€â”€ main.py                # FastAPI ä¸»å…¥å£
â”‚   â”œâ”€â”€ models.py              # Pydantic æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ auth.py                # ç”¨æˆ·è®¤è¯
â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“æ“ä½œ
â”‚   â”œâ”€â”€ inference_utils.py     # vLLM æ¨ç†å·¥å…·
â”‚   â”œâ”€â”€ training_utils.py      # oumi è®­ç»ƒå·¥å…·
â”‚   â”œâ”€â”€ evaluation_utils.py    # æ¨¡å‹è¯„ä¼°å·¥å…·
â”‚   â”œâ”€â”€ huggingface_utils.py   # HuggingFace å·¥å…·
â”‚   â”œâ”€â”€ requirements.txt       # Python ä¾èµ–
â”‚   â”œâ”€â”€ static/                # å‰ç«¯é™æ€æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ js/
â”‚   â”œâ”€â”€ models/                # ä¸‹è½½çš„æ¨¡å‹å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ datasets/              # ä¸‹è½½çš„æ•°æ®é›†å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ trainedmodels/         # è®­ç»ƒåçš„æ¨¡å‹å­˜å‚¨ç›®å½•
â”‚   â”œâ”€â”€ logs/                  # æ—¥å¿—ç›®å½•
â”‚   â”œâ”€â”€ training_configs/      # è®­ç»ƒé…ç½®ç›®å½•
â”‚   â”œâ”€â”€ evaluation_configs/    # è¯„ä¼°é…ç½®ç›®å½•
â”‚   â””â”€â”€ evaluation_results/    # è¯„ä¼°ç»“æœç›®å½•
â”œâ”€â”€ assets/                    # é¡¹ç›®èµ„æºæ–‡ä»¶
â”œâ”€â”€ README.md                  # é¡¹ç›®è¯´æ˜
â”œâ”€â”€ DEPLOYMENT.md              # éƒ¨ç½²æŒ‡å—ï¼ˆæœ¬æ–‡ä»¶ï¼‰
â””â”€â”€ chat.py                    # å‘½ä»¤è¡ŒèŠå¤©è„šæœ¬
```

---

## âš ï¸ ç‰ˆæœ¬å…¼å®¹æ€§è¯´æ˜

### é‡è¦ï¼šPyTorchã€vLLM å’Œ oumi ç‰ˆæœ¬å¿…é¡»å…¼å®¹

| ç»„åˆ | PyTorch | vLLM | oumi | çŠ¶æ€ |
|------|---------|------|------|------|
| âœ… æ¨è | 2.8.0 | 0.10.2 | 0.6.0 | å·²æµ‹è¯•é€šè¿‡ |
| âŒ ä¸å…¼å®¹ | 2.8.0 | 0.8.x | 0.6.0 | vLLM éœ€è¦ torch 2.6 |
| âŒ ä¸å…¼å®¹ | 2.6.0 | 0.8.x | 0.6.0 | oumi éœ€è¦ torch>=2.6 |

### ç‰ˆæœ¬çº¦æŸ
- **oumi 0.6.0**: éœ€è¦ `torch>=2.6,<2.9.0`
- **vLLM 0.10.2**: éœ€è¦ `torch==2.8.0`
- **PyTorch 2.8.0**: éœ€è¦ CUDA 12.1+

---

## ğŸ”§ å¸¸è§é—®é¢˜

### 1. vLLM å®‰è£…å¤±è´¥

```bash
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ PyTorch ç‰ˆæœ¬
pip install torch==2.8.0 --index-url https://download.pytorch.org/whl/cu128
pip install vllm==0.10.2
```

### 2. CUDA ç‰ˆæœ¬ä¸åŒ¹é…

```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvidia-smi
python -c "import torch; print(torch.version.cuda)"

# ç¡®ä¿ NVIDIA é©±åŠ¨ç‰ˆæœ¬ >= 525
```

### 3. protobuf ç‰ˆæœ¬å†²çª

```bash
# oumi éœ€è¦ protobuf >= 6.32
pip install "protobuf>=6.32,<7"
```

### 4. HuggingFace ä¸‹è½½æ…¢

```bash
# ä½¿ç”¨å›½å†…é•œåƒ
export HF_ENDPOINT=https://hf-mirror.com
```

### 5. WSL2 ç¯å¢ƒé…ç½®

```bash
# ç¡®ä¿ WSL2 å¯ä»¥è®¿é—® GPU
nvidia-smi

# å¦‚æœå¤±è´¥ï¼Œéœ€è¦å®‰è£… NVIDIA CUDA on WSL
# å‚è€ƒ: https://docs.nvidia.com/cuda/wsl-user-guide/
```

---

## ğŸŒ ç«¯å£è¯´æ˜

| æœåŠ¡ | é»˜è®¤ç«¯å£ | è¯´æ˜ |
|------|----------|------|
| Web åº”ç”¨ | 8888 | ä¸»åº”ç”¨ç«¯å£ |
| vLLM æ¨ç† | 8000-8099 | æ¨ç†æœåŠ¡ç«¯å£èŒƒå›´ |

---

## ğŸ“ æ•°æ®åº“

é¡¹ç›®ä½¿ç”¨ SQLite æ•°æ®åº“ï¼Œé¦–æ¬¡å¯åŠ¨æ—¶ä¼šè‡ªåŠ¨åˆ›å»ºï¼š

- æ•°æ®åº“æ–‡ä»¶: `modelverse/modelverse.db`
- è‡ªåŠ¨åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜è´¦æˆ·

---

## ğŸ”’ é»˜è®¤è´¦æˆ·

| ç”¨æˆ·å | å¯†ç  | è§’è‰² |
|--------|------|------|
| admin | admin123 | ç®¡ç†å‘˜ |

> âš ï¸ ç”Ÿäº§ç¯å¢ƒè¯·åŠ¡å¿…ä¿®æ”¹é»˜è®¤å¯†ç ï¼

---

## ğŸ“Š åŠŸèƒ½è¯´æ˜

### 1. èµ„æºç®¡ç†
- ä» HuggingFace ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†
- æ”¯æŒå›½å†…é•œåƒåŠ é€Ÿ
- è‡ªåŠ¨ç®¡ç†æœ¬åœ°å­˜å‚¨

### 2. æ¨ç†æœåŠ¡
- åŸºäº vLLM çš„é«˜æ€§èƒ½æ¨ç†
- OpenAI å…¼å®¹ API
- å†…ç½®èŠå¤©ç•Œé¢

### 3. æ¨¡å‹è®­ç»ƒ
- åŸºäº oumi æ¡†æ¶
- æ”¯æŒ SFT/LoRA ç­‰è®­ç»ƒæ–¹å¼
- å®æ—¶è®­ç»ƒæ—¥å¿—

### 4. æ¨¡å‹è¯„ä¼°
- å¤šç§è¯„ä¼°åŸºå‡†
- è‡ªåŠ¨è¯„ä¼°æŠ¥å‘Š

---

## ğŸ›¡ï¸ ç”Ÿäº§éƒ¨ç½²å»ºè®®

### 1. ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨

```bash
# ä½¿ç”¨ nohup
nohup uvicorn main:app --host 0.0.0.0 --port 8888 > server.log 2>&1 &

# æˆ–ä½¿ç”¨ systemd æœåŠ¡
```

### 2. åå‘ä»£ç† (Nginx)

```nginx
server {
    listen 80;
    server_name your-domain.com;
    
    location / {
        proxy_pass http://127.0.0.1:8888;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
    }
}
```

### 3. ç¯å¢ƒå˜é‡é…ç½®

```bash
# åˆ›å»º .env æ–‡ä»¶
HF_ENDPOINT=https://hf-mirror.com
HF_HUB_ENABLE_HF_TRANSFER=0
```

---

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æäº¤ Issue: https://github.com/Guiwith/ModelVerse/issues

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªå¼€æºåŸåˆ™ï¼Œå®Œå…¨å¼€æºã€‚æ ¸å¿ƒä¾èµ– oumi æ¡†æ¶ã€‚
